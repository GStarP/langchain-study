{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to use a model to call tools](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = getpass.getpass()\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat', \n",
    "    openai_api_key=os.environ['OPENAI_API_KEY'], \n",
    "    openai_api_base='https://api.deepseek.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, our DeepSeek model is not the same as OpenAI in tool calling.\n",
    "\n",
    "Let's dive into the nature of tool calling. See [here](https://python.langchain.com/v0.1/docs/use_cases/tool_use/prompting/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_comment\n",
      "Give negative comment to this game.\n",
      "{'game': {'title': 'Game', 'type': 'string'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Zelda seems not better than Genshin Impact...'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool should be a normal function, with params and returns\n",
    "# Here we define a mock tool, in the real world, it may be a search-engine api or something else\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def negative_comment(game: str) -> str:\n",
    "  '''Give negative comment to this game.'''\n",
    "  return f'{game} seems not better than Genshin Impact...'\n",
    "\n",
    "print(negative_comment.name)\n",
    "print(negative_comment.description)\n",
    "print(negative_comment.args)\n",
    "negative_comment.invoke('Zelda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative_comment(game: str) -> str - Give negative comment to this game.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should tell LLM about the tool's info, which means that\n",
    "# LLM will choose tool to use according to its description (and may also args)\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "rendered_tools = render_text_description([negative_comment])\n",
    "rendered_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = f'''You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system_prompt), ('user', 'Give negative comment to {input}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'negative_comment', 'arguments': {'game': 'Zelda'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Through prompt, we transform natural language instruction => formatted tool call\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOutputParser()\n",
    "chain.invoke({'input': 'Zelda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zelda seems not better than Genshin Impact...'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we directly do tool calling\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = prompt | model | JsonOutputParser() | itemgetter('arguments') | negative_comment\n",
    "chain.invoke({'input': 'Zelda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zelda is the best game in the world !!!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we have multiple tools to choose, how to do decision?\n",
    "# According to input, the LLM will choose one tool, we use tool.name to locate\n",
    "@tool\n",
    "def positive_comment(game: str) -> str:\n",
    "  '''Give positive comment to this game.'''\n",
    "  return f'{game} is the best game in the world !!!'\n",
    "\n",
    "tools = [negative_comment, positive_comment]\n",
    "\n",
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output['name']]\n",
    "    return itemgetter('arguments') | chosen_tool\n",
    "\n",
    "\n",
    "rendered_tools = render_text_description([negative_comment, positive_comment])\n",
    "system_prompt = f'''You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system_prompt), ('user', 'If {input} belongs to Zelda series, give positive comment. Otherwise give negative comment.')]\n",
    ")\n",
    "\n",
    "chain = prompt | model | JsonOutputParser() | tool_chain\n",
    "chain.invoke({\"input\": \"Zelda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DotA2 seems not better than Genshin Impact...'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"DotA2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'positive_comment',\n",
       " 'arguments': {'game': 'Zelda'},\n",
       " 'output': 'Zelda is the best game in the world !!!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also return tool input\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=tool_chain)\n",
    "chain.invoke({\"input\": \"Zelda\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
